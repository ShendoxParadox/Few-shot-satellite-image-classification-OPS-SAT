{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcdcd3ca",
   "metadata": {},
   "source": [
    "# OPS-SAT case starter-kit notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad0860",
   "metadata": {},
   "source": [
    "ESA's [Kelvins](https://kelvins.esa.int) competition \"[the OPS-SAT case](https://kelvins.esa.int/opssat/home/)\" is a novel data-centric challenge that asks you to work with the raw data of a satellite and very few provided labels to find the best parameters for a given machine learning model. Compared to previous competitions on Kelvins (like the [Pose Estimation](https://kelvins.esa.int/pose-estimation-2021/) or the [Proba-V Super-resolution challenge](https://kelvins.esa.int/proba-v-super-resolution/)) where the test-set is provided and the infered results are submitted, for the OPS-SAT case, we will run inference on the Kelvins server directly! This notebooks contains examples on how you can load your data and train an **EfficientNetLite0** model by only using the 80-labeled images provided. Therefore, the directory `images`, containing unlabeld patches and included in the training dataset is not used for this notebook. However, competitors are encouraged to use these patches to improve the model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403eeb5a",
   "metadata": {},
   "source": [
    "# 1. Module imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d88f44",
   "metadata": {},
   "source": [
    "If you do not have a GPU, uncomment and run the next commands.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3f6cde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:31.525217Z",
     "start_time": "2023-04-09T20:42:31.521341Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.16 (main, Mar  8 2023, 14:00:05) \\n[GCC 11.2.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7c8f9d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:31.887841Z",
     "start_time": "2023-04-09T20:42:31.711974Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/zsh: /home/ramez/miniconda3/envs/thesis/lib/libtinfo.so.6: no version information available (required by /usr/bin/zsh)\n",
      "Python 3.9.16\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb8fddce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:32.267814Z",
     "start_time": "2023-04-09T20:42:32.094731Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/zsh: /home/ramez/miniconda3/envs/thesis/lib/libtinfo.so.6: no version information available (required by /usr/bin/zsh)\n",
      "/home/ramez/miniconda3/envs/thesis/bin/python\n"
     ]
    }
   ],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3aecaa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:33.914315Z",
     "start_time": "2023-04-09T20:42:33.911985Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1fd19-d4ef-4a54-877e-9d06a9049737",
   "metadata": {},
   "source": [
    "#### GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e02f8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:36.255529Z",
     "start_time": "2023-04-09T20:42:34.328075Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/zsh: /home/ramez/miniconda3/envs/thesis/lib/libtinfo.so.6: no version information available (required by /usr/bin/zsh)\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "234eba6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:36.260638Z",
     "start_time": "2023-04-09T20:42:36.257966Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea21b9b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:36.327202Z",
     "start_time": "2023-04-09T20:42:36.262029Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f73af189",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:36.336400Z",
     "start_time": "2023-04-09T20:42:36.333721Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80fbbb42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:36.345491Z",
     "start_time": "2023-04-09T20:42:36.343286Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Local EfficientNetLite (Customized by the Competition)\n",
    "from efficientnet_lite import EfficientNetLiteB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6face98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:36.349008Z",
     "start_time": "2023-04-09T20:42:36.346850Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb004876",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:36.353039Z",
     "start_time": "2023-04-09T20:42:36.350804Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22d591c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:36.719018Z",
     "start_time": "2023-04-09T20:42:36.716802Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7cffd18-bb07-4455-8292-3cd846d3139e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d5167dd-ad8d-41ab-9c7c-ace8e0c7c765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdcaf42f-1499-4cde-a474-ee694d25d7eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import accumulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262ab8b0-57fa-4a40-9ebc-fd2e9809942f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "539eda62",
   "metadata": {},
   "source": [
    "# 2. Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec32f1b",
   "metadata": {},
   "source": [
    "You can use this function to load your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f270337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:37.464808Z",
     "start_time": "2023-04-09T20:42:37.461420Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_images_from_path(dataset_path):\n",
    "    \"\"\" Get images from path and normalize them applying channel-level normalization. \"\"\"\n",
    "\n",
    "    # loading all images in one large batch\n",
    "    tf_eval_data = tf.keras.utils.image_dataset_from_directory(dataset_path, image_size=input_shape[:2], shuffle=False, \n",
    "                                                               batch_size=100000)\n",
    "\n",
    "    # extract images and targets\n",
    "    for tf_eval_images, tf_eval_targets in tf_eval_data:\n",
    "        break\n",
    "\n",
    "    return tf.convert_to_tensor(tf_eval_images), tf_eval_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cec9e1",
   "metadata": {},
   "source": [
    "# 4. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3939168c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:42.576907Z",
     "start_time": "2023-04-09T20:42:42.574308Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_path_train=\"/home/ramez/Politechnika_Slaska_MSc/Thesis/Competition/Data/images_copy_processed/\"\n",
    "dataset_path_train_val = \"/home/ramez/Politechnika_Slaska_MSc/Thesis/Competition/Data/ops_sat_train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e57cb03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:43.086890Z",
     "start_time": "2023-04-09T20:42:43.084818Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path_test = \"/home/ramez/Politechnika_Slaska_MSc/Thesis/Competition/Data/ops_sat_test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7277b8",
   "metadata": {},
   "source": [
    "In this notebook, classical supervised learning is used. Therefore, remember to remove the subdirectory `images` containing unlabeled patches before loading the dataset to perform training correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5fe37a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:38.494116Z",
     "start_time": "2023-04-09T20:42:38.491962Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_shape = (200, 200, 3)   # input_shape is (height, width, number of channels) for images\n",
    "num_classes = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "535d9f57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:44.029535Z",
     "start_time": "2023-04-09T20:42:43.904140Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 227 files belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "#Loading dataset\n",
    "x_train_val, y_train_val = get_images_from_path(dataset_path_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "176ad7e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:44.501742Z",
     "start_time": "2023-04-09T20:42:44.458845Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 files belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "#Loading dataset\n",
    "x_test, y_test = get_images_from_path(dataset_path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed865db",
   "metadata": {},
   "source": [
    "# 5. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f4a84c-e53f-42e5-b7ea-12893a82a5d1",
   "metadata": {},
   "source": [
    "The network architecture used for OPS-SAT is **EfficientNetLite0**. We would like to thank Sebastian for making a Keras implementation of EfficientNetLite publicly available under the Apache 2.0 License: https://github.com/sebastian-sz/efficientnet-lite-keras. Our Version of this code has been modified to better fit our purposes. For example, we removed the ReLU \"stem_activation\" to better match a related efficientnet pytorch implementation. In any way, **you have to use the model architecture that we provide in our [starter-kit](https://gitlab.com/EuropeanSpaceAgency/the_opssat_case_starter_kit).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a9bc3a-67ab-4e37-9a2f-aab98c8c5b25",
   "metadata": {},
   "source": [
    "### Load The Model With ImageNet Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba86fe85-998e-4704-bb76-18af67274166",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compile The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c29753-9cbf-4149-a938-ceec8435dce0",
   "metadata": {},
   "source": [
    "### Early Stopping and Best Model Callbacks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340a085b-c09c-4892-968a-8eeb2c556ce1",
   "metadata": {},
   "source": [
    "We provide now an example on how you can train your model by using standard supervised learning. Training loss (`SparseCategoricalCrossentropy`) and `Accuracy` are shown for simplicity and for an easier interpretation of the training outcome, despite your submission will be evaluated by using the metric **1 - Cohen's kappa** [metric](https://en.wikipedia.org/wiki/Cohen's_kappa). For more information on scoring, please refer to [Scoring](https://kelvins.esa.int/opssat/scoring/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "593c7f99-4e05-4b40-8cc7-e7c4b84e3452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    global model\n",
    "    global early_stopping\n",
    "    global checkpoint\n",
    "    \n",
    "    model = EfficientNetLiteB0(classes=num_classes, weights='imagenet', input_shape=input_shape, classifier_activation=None, include_top = False)\n",
    "    x = model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=model.input, outputs=output_layer)\n",
    "    # model.summary()\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=9)\n",
    "    checkpoint = ModelCheckpoint('best_weights.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc53411-de66-41a5-bdfe-47e6b2b94462",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Without K fold Cross Validation but with TensorBoard (With Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ae962a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:49.259862Z",
     "start_time": "2023-04-09T20:42:49.257217Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorboard_callback = TensorBoard(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24568775",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:43:38.960294Z",
     "start_time": "2023-04-09T20:42:50.924320Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "# history = model.fit(x_train_val, y_train_val, validation_data=(x_test, y_test), epochs= 100, verbose=1, batch_size=8, \n",
    "#                         callbacks=[early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "faa7c10b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:45:36.527054Z",
     "start_time": "2023-04-09T20:44:17.923419Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=./logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9899b0-587d-4c9a-b9b5-ec61295e2e48",
   "metadata": {},
   "source": [
    "### With K fold Cross Validation but without TensorBoard (With Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12efbbf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:47.226837Z",
     "start_time": "2023-04-09T20:42:47.224186Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a930432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:43:57.248568Z",
     "start_time": "2023-04-09T20:43:57.245137Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1a_ same\n",
      "block2a_ ((1, 1), (1, 1))\n",
      "block2a_ valid\n",
      "block2b_ same\n",
      "block3a_ ((2, 2), (2, 2))\n",
      "block3a_ valid\n",
      "block3b_ same\n",
      "block4a_ ((1, 1), (1, 1))\n",
      "block4a_ valid\n",
      "block4b_ same\n",
      "block4c_ same\n",
      "block5a_ same\n",
      "block5b_ same\n",
      "block5c_ same\n",
      "block6a_ ((2, 2), (2, 2))\n",
      "block6a_ valid\n",
      "block6b_ same\n",
      "block6c_ same\n",
      "block6d_ same\n",
      "block7a_ same\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 15:37:51.011225: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 9.2.148, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - ETA: 0s - loss: 1.6643 - sparse_categorical_accuracy: 0.4530"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramez/miniconda3/envs/thesis/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 10s 220ms/step - loss: 1.6643 - sparse_categorical_accuracy: 0.4530 - val_loss: 2.9914 - val_sparse_categorical_accuracy: 0.2391\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 3s 136ms/step - loss: 0.9458 - sparse_categorical_accuracy: 0.7017 - val_loss: 1.8259 - val_sparse_categorical_accuracy: 0.4130\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 3s 123ms/step - loss: 0.6133 - sparse_categorical_accuracy: 0.7956 - val_loss: 2.5671 - val_sparse_categorical_accuracy: 0.3261\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 0.6132 - sparse_categorical_accuracy: 0.8122 - val_loss: 3.1164 - val_sparse_categorical_accuracy: 0.3478\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 3s 119ms/step - loss: 0.6408 - sparse_categorical_accuracy: 0.8011 - val_loss: 4.0098 - val_sparse_categorical_accuracy: 0.3261\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 3s 118ms/step - loss: 0.5303 - sparse_categorical_accuracy: 0.8232 - val_loss: 2.0762 - val_sparse_categorical_accuracy: 0.5217\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 0.4212 - sparse_categorical_accuracy: 0.8619 - val_loss: 2.6445 - val_sparse_categorical_accuracy: 0.6087\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 3s 121ms/step - loss: 0.3857 - sparse_categorical_accuracy: 0.8785 - val_loss: 2.6366 - val_sparse_categorical_accuracy: 0.6522\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 3s 120ms/step - loss: 0.4416 - sparse_categorical_accuracy: 0.8619 - val_loss: 2.5446 - val_sparse_categorical_accuracy: 0.5870\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.4341 - sparse_categorical_accuracy: 0.8674 - val_loss: 2.3682 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 3s 123ms/step - loss: 0.5284 - sparse_categorical_accuracy: 0.8508 - val_loss: 1.9850 - val_sparse_categorical_accuracy: 0.6522\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 3s 123ms/step - loss: 0.4674 - sparse_categorical_accuracy: 0.8674 - val_loss: 2.1134 - val_sparse_categorical_accuracy: 0.6087\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.2344 - sparse_categorical_accuracy: 0.9392 - val_loss: 2.2505 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 3s 142ms/step - loss: 0.2880 - sparse_categorical_accuracy: 0.9171 - val_loss: 1.5612 - val_sparse_categorical_accuracy: 0.6087\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 3s 126ms/step - loss: 0.2959 - sparse_categorical_accuracy: 0.8950 - val_loss: 2.2026 - val_sparse_categorical_accuracy: 0.5217\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 3s 128ms/step - loss: 0.3496 - sparse_categorical_accuracy: 0.8950 - val_loss: 2.6154 - val_sparse_categorical_accuracy: 0.6304\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 3s 114ms/step - loss: 0.2825 - sparse_categorical_accuracy: 0.9171 - val_loss: 1.6613 - val_sparse_categorical_accuracy: 0.6957\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 3s 126ms/step - loss: 0.2547 - sparse_categorical_accuracy: 0.8840 - val_loss: 1.6137 - val_sparse_categorical_accuracy: 0.6087\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 3s 126ms/step - loss: 0.3286 - sparse_categorical_accuracy: 0.8840 - val_loss: 2.5589 - val_sparse_categorical_accuracy: 0.5435\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 3s 119ms/step - loss: 0.2775 - sparse_categorical_accuracy: 0.9116 - val_loss: 1.9381 - val_sparse_categorical_accuracy: 0.5870\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 0.1647 - sparse_categorical_accuracy: 0.9669 - val_loss: 2.0398 - val_sparse_categorical_accuracy: 0.6087\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 3s 126ms/step - loss: 0.1662 - sparse_categorical_accuracy: 0.9503 - val_loss: 1.7047 - val_sparse_categorical_accuracy: 0.6957\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 3s 151ms/step - loss: 0.1463 - sparse_categorical_accuracy: 0.9558 - val_loss: 1.5071 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 3s 121ms/step - loss: 0.2180 - sparse_categorical_accuracy: 0.9282 - val_loss: 1.5795 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 0.2159 - sparse_categorical_accuracy: 0.9282 - val_loss: 2.5495 - val_sparse_categorical_accuracy: 0.5870\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 0.3740 - sparse_categorical_accuracy: 0.8729 - val_loss: 2.1813 - val_sparse_categorical_accuracy: 0.6522\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 3s 123ms/step - loss: 0.2194 - sparse_categorical_accuracy: 0.9227 - val_loss: 5.3950 - val_sparse_categorical_accuracy: 0.4130\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.1871 - sparse_categorical_accuracy: 0.9392 - val_loss: 2.4538 - val_sparse_categorical_accuracy: 0.5870\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 3s 121ms/step - loss: 0.1968 - sparse_categorical_accuracy: 0.9282 - val_loss: 3.0276 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 0.1671 - sparse_categorical_accuracy: 0.9282 - val_loss: 1.7869 - val_sparse_categorical_accuracy: 0.7174\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 3s 146ms/step - loss: 0.1582 - sparse_categorical_accuracy: 0.9337 - val_loss: 1.5062 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.1605 - sparse_categorical_accuracy: 0.9227 - val_loss: 1.5712 - val_sparse_categorical_accuracy: 0.7609\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.1853 - sparse_categorical_accuracy: 0.9503 - val_loss: 1.5893 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 3s 149ms/step - loss: 0.2312 - sparse_categorical_accuracy: 0.9448 - val_loss: 1.4668 - val_sparse_categorical_accuracy: 0.6522\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 3s 123ms/step - loss: 0.2205 - sparse_categorical_accuracy: 0.9171 - val_loss: 2.1099 - val_sparse_categorical_accuracy: 0.6522\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 0.2748 - sparse_categorical_accuracy: 0.9227 - val_loss: 2.5285 - val_sparse_categorical_accuracy: 0.5652\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 3s 128ms/step - loss: 0.2114 - sparse_categorical_accuracy: 0.9282 - val_loss: 2.1609 - val_sparse_categorical_accuracy: 0.5870\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.1805 - sparse_categorical_accuracy: 0.9503 - val_loss: 2.7915 - val_sparse_categorical_accuracy: 0.4783\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 3s 126ms/step - loss: 0.1279 - sparse_categorical_accuracy: 0.9613 - val_loss: 1.6572 - val_sparse_categorical_accuracy: 0.6087\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.0803 - sparse_categorical_accuracy: 0.9779 - val_loss: 1.9134 - val_sparse_categorical_accuracy: 0.6522\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.0548 - sparse_categorical_accuracy: 0.9890 - val_loss: 1.7916 - val_sparse_categorical_accuracy: 0.6087\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 3s 126ms/step - loss: 0.1153 - sparse_categorical_accuracy: 0.9669 - val_loss: 2.1202 - val_sparse_categorical_accuracy: 0.6087\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 3s 132ms/step - loss: 0.0782 - sparse_categorical_accuracy: 0.9779 - val_loss: 2.0686 - val_sparse_categorical_accuracy: 0.6304\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 3s 144ms/step - loss: 0.0651 - sparse_categorical_accuracy: 0.9834 - val_loss: 1.4438 - val_sparse_categorical_accuracy: 0.6304\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0536 - sparse_categorical_accuracy: 0.9834 - val_loss: 1.2058 - val_sparse_categorical_accuracy: 0.7826\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 3s 126ms/step - loss: 0.0269 - sparse_categorical_accuracy: 0.9945 - val_loss: 1.2963 - val_sparse_categorical_accuracy: 0.7174\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 3s 132ms/step - loss: 0.0382 - sparse_categorical_accuracy: 0.9834 - val_loss: 1.5903 - val_sparse_categorical_accuracy: 0.6522\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 3s 131ms/step - loss: 0.0831 - sparse_categorical_accuracy: 0.9669 - val_loss: 2.1734 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 3s 128ms/step - loss: 0.0608 - sparse_categorical_accuracy: 0.9724 - val_loss: 1.9420 - val_sparse_categorical_accuracy: 0.6522\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 3s 134ms/step - loss: 0.0309 - sparse_categorical_accuracy: 0.9945 - val_loss: 1.3584 - val_sparse_categorical_accuracy: 0.6957\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.0395 - sparse_categorical_accuracy: 0.9834 - val_loss: 1.5167 - val_sparse_categorical_accuracy: 0.7391\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0785 - sparse_categorical_accuracy: 0.9724 - val_loss: 1.1641 - val_sparse_categorical_accuracy: 0.7174\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.1368 - sparse_categorical_accuracy: 0.9448 - val_loss: 1.3972 - val_sparse_categorical_accuracy: 0.7174\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 3s 128ms/step - loss: 0.0606 - sparse_categorical_accuracy: 0.9890 - val_loss: 2.1149 - val_sparse_categorical_accuracy: 0.6522\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 3s 132ms/step - loss: 0.0818 - sparse_categorical_accuracy: 0.9724 - val_loss: 1.7307 - val_sparse_categorical_accuracy: 0.6522\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 3s 153ms/step - loss: 0.0391 - sparse_categorical_accuracy: 0.9890 - val_loss: 1.0222 - val_sparse_categorical_accuracy: 0.7609\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 3s 133ms/step - loss: 0.0425 - sparse_categorical_accuracy: 0.9834 - val_loss: 1.2428 - val_sparse_categorical_accuracy: 0.7174\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.0767 - sparse_categorical_accuracy: 0.9834 - val_loss: 1.4548 - val_sparse_categorical_accuracy: 0.7391\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.1703 - sparse_categorical_accuracy: 0.9282 - val_loss: 1.2358 - val_sparse_categorical_accuracy: 0.6304\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 3s 135ms/step - loss: 0.1367 - sparse_categorical_accuracy: 0.9613 - val_loss: 1.7201 - val_sparse_categorical_accuracy: 0.6522\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 3s 133ms/step - loss: 0.1693 - sparse_categorical_accuracy: 0.9448 - val_loss: 1.7471 - val_sparse_categorical_accuracy: 0.7174\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 3s 132ms/step - loss: 0.1125 - sparse_categorical_accuracy: 0.9724 - val_loss: 2.0554 - val_sparse_categorical_accuracy: 0.5870\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 0.3337 - sparse_categorical_accuracy: 0.9171 - val_loss: 1.5566 - val_sparse_categorical_accuracy: 0.6957\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 3s 135ms/step - loss: 0.0858 - sparse_categorical_accuracy: 0.9724 - val_loss: 3.3168 - val_sparse_categorical_accuracy: 0.5870\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.1748 - sparse_categorical_accuracy: 0.9558 - val_loss: 2.2836 - val_sparse_categorical_accuracy: 0.6304\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 3s 132ms/step - loss: 0.1688 - sparse_categorical_accuracy: 0.9503 - val_loss: 2.8882 - val_sparse_categorical_accuracy: 0.5652\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 3s 134ms/step - loss: 0.0764 - sparse_categorical_accuracy: 0.9724 - val_loss: 2.5335 - val_sparse_categorical_accuracy: 0.6304\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.0469 - sparse_categorical_accuracy: 0.9890 - val_loss: 1.7031 - val_sparse_categorical_accuracy: 0.6304\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 3s 137ms/step - loss: 0.1526 - sparse_categorical_accuracy: 0.9724 - val_loss: 1.6453 - val_sparse_categorical_accuracy: 0.7609\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 3s 132ms/step - loss: 0.0759 - sparse_categorical_accuracy: 0.9779 - val_loss: 1.8326 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 3s 135ms/step - loss: 0.0921 - sparse_categorical_accuracy: 0.9724 - val_loss: 2.3763 - val_sparse_categorical_accuracy: 0.5870\n",
      "2/2 [==============================] - 1s 439ms/step - loss: 2.3763 - sparse_categorical_accuracy: 0.5870\n",
      "block1a_ same\n",
      "block2a_ ((1, 1), (1, 1))\n",
      "block2a_ valid\n",
      "block2b_ same\n",
      "block3a_ ((2, 2), (2, 2))\n",
      "block3a_ valid\n",
      "block3b_ same\n",
      "block4a_ ((1, 1), (1, 1))\n",
      "block4a_ valid\n",
      "block4b_ same\n",
      "block4c_ same\n",
      "block5a_ same\n",
      "block5b_ same\n",
      "block5c_ same\n",
      "block6a_ ((2, 2), (2, 2))\n",
      "block6a_ valid\n",
      "block6b_ same\n",
      "block6c_ same\n",
      "block6d_ same\n",
      "block7a_ same\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 9s 189ms/step - loss: 1.7390 - sparse_categorical_accuracy: 0.4696 - val_loss: 3.0661 - val_sparse_categorical_accuracy: 0.1957\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 3s 154ms/step - loss: 0.9771 - sparse_categorical_accuracy: 0.6796 - val_loss: 2.5648 - val_sparse_categorical_accuracy: 0.2826\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 3s 123ms/step - loss: 0.7593 - sparse_categorical_accuracy: 0.7569 - val_loss: 2.7160 - val_sparse_categorical_accuracy: 0.3478\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.6823 - sparse_categorical_accuracy: 0.7624 - val_loss: 4.2355 - val_sparse_categorical_accuracy: 0.3043\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.6768 - sparse_categorical_accuracy: 0.7790 - val_loss: 2.4812 - val_sparse_categorical_accuracy: 0.5435\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 3s 121ms/step - loss: 0.6073 - sparse_categorical_accuracy: 0.8122 - val_loss: 2.6019 - val_sparse_categorical_accuracy: 0.5435\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.5998 - sparse_categorical_accuracy: 0.7845 - val_loss: 3.1874 - val_sparse_categorical_accuracy: 0.5217\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.4242 - sparse_categorical_accuracy: 0.8674 - val_loss: 2.0754 - val_sparse_categorical_accuracy: 0.5870\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 3s 152ms/step - loss: 0.3502 - sparse_categorical_accuracy: 0.8950 - val_loss: 1.1876 - val_sparse_categorical_accuracy: 0.7391\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 3s 120ms/step - loss: 0.3743 - sparse_categorical_accuracy: 0.8895 - val_loss: 1.9215 - val_sparse_categorical_accuracy: 0.6087\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 3s 119ms/step - loss: 0.3377 - sparse_categorical_accuracy: 0.8840 - val_loss: 1.4059 - val_sparse_categorical_accuracy: 0.7391\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 3s 116ms/step - loss: 0.4961 - sparse_categorical_accuracy: 0.8122 - val_loss: 2.4943 - val_sparse_categorical_accuracy: 0.5652\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 3s 118ms/step - loss: 0.4116 - sparse_categorical_accuracy: 0.8729 - val_loss: 1.8496 - val_sparse_categorical_accuracy: 0.6304\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 3s 118ms/step - loss: 0.4041 - sparse_categorical_accuracy: 0.8840 - val_loss: 1.6865 - val_sparse_categorical_accuracy: 0.6957\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 3s 118ms/step - loss: 0.3319 - sparse_categorical_accuracy: 0.9061 - val_loss: 2.0720 - val_sparse_categorical_accuracy: 0.5217\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 3s 120ms/step - loss: 0.2756 - sparse_categorical_accuracy: 0.9171 - val_loss: 2.5829 - val_sparse_categorical_accuracy: 0.5435\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 3s 118ms/step - loss: 0.3442 - sparse_categorical_accuracy: 0.8895 - val_loss: 2.7822 - val_sparse_categorical_accuracy: 0.4783\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 3s 118ms/step - loss: 0.4559 - sparse_categorical_accuracy: 0.8564 - val_loss: 1.9246 - val_sparse_categorical_accuracy: 0.5435\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 3s 119ms/step - loss: 0.4758 - sparse_categorical_accuracy: 0.8785 - val_loss: 1.5372 - val_sparse_categorical_accuracy: 0.6087\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 3s 118ms/step - loss: 0.2553 - sparse_categorical_accuracy: 0.9006 - val_loss: 2.4929 - val_sparse_categorical_accuracy: 0.4783\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 3s 120ms/step - loss: 0.1660 - sparse_categorical_accuracy: 0.9392 - val_loss: 2.0833 - val_sparse_categorical_accuracy: 0.5652\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 3s 151ms/step - loss: 0.0862 - sparse_categorical_accuracy: 0.9724 - val_loss: 1.0894 - val_sparse_categorical_accuracy: 0.7826\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 0.1133 - sparse_categorical_accuracy: 0.9669 - val_loss: 1.2855 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 0.1137 - sparse_categorical_accuracy: 0.9724 - val_loss: 1.3160 - val_sparse_categorical_accuracy: 0.6304\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 3s 135ms/step - loss: 0.1145 - sparse_categorical_accuracy: 0.9392 - val_loss: 1.1981 - val_sparse_categorical_accuracy: 0.7609\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.1815 - sparse_categorical_accuracy: 0.9448 - val_loss: 1.0088 - val_sparse_categorical_accuracy: 0.6957\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 3s 132ms/step - loss: 0.1653 - sparse_categorical_accuracy: 0.9282 - val_loss: 1.2012 - val_sparse_categorical_accuracy: 0.7174\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 0.1119 - sparse_categorical_accuracy: 0.9613 - val_loss: 2.0415 - val_sparse_categorical_accuracy: 0.6522\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 3s 132ms/step - loss: 0.1726 - sparse_categorical_accuracy: 0.9558 - val_loss: 1.0705 - val_sparse_categorical_accuracy: 0.7826\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.1301 - sparse_categorical_accuracy: 0.9669 - val_loss: 2.0475 - val_sparse_categorical_accuracy: 0.6522\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 3s 135ms/step - loss: 0.1446 - sparse_categorical_accuracy: 0.9448 - val_loss: 1.7039 - val_sparse_categorical_accuracy: 0.7174\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 3s 135ms/step - loss: 0.2664 - sparse_categorical_accuracy: 0.9061 - val_loss: 2.5131 - val_sparse_categorical_accuracy: 0.5652\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 3s 134ms/step - loss: 0.2692 - sparse_categorical_accuracy: 0.9006 - val_loss: 4.5344 - val_sparse_categorical_accuracy: 0.4130\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.1908 - sparse_categorical_accuracy: 0.9448 - val_loss: 3.2255 - val_sparse_categorical_accuracy: 0.5652\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.2471 - sparse_categorical_accuracy: 0.9227 - val_loss: 1.8130 - val_sparse_categorical_accuracy: 0.5870\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.2622 - sparse_categorical_accuracy: 0.8950 - val_loss: 1.8093 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 3s 128ms/step - loss: 0.1702 - sparse_categorical_accuracy: 0.9613 - val_loss: 1.4104 - val_sparse_categorical_accuracy: 0.5870\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.1618 - sparse_categorical_accuracy: 0.9558 - val_loss: 1.2231 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.0628 - sparse_categorical_accuracy: 0.9779 - val_loss: 1.0695 - val_sparse_categorical_accuracy: 0.7826\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 3s 134ms/step - loss: 0.1197 - sparse_categorical_accuracy: 0.9558 - val_loss: 1.1151 - val_sparse_categorical_accuracy: 0.7174\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 0.1547 - sparse_categorical_accuracy: 0.9448 - val_loss: 1.4880 - val_sparse_categorical_accuracy: 0.6522\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.4880 - sparse_categorical_accuracy: 0.6522\n",
      "block1a_ same\n",
      "block2a_ ((1, 1), (1, 1))\n",
      "block2a_ valid\n",
      "block2b_ same\n",
      "block3a_ ((2, 2), (2, 2))\n",
      "block3a_ valid\n",
      "block3b_ same\n",
      "block4a_ ((1, 1), (1, 1))\n",
      "block4a_ valid\n",
      "block4b_ same\n",
      "block4c_ same\n",
      "block5a_ same\n",
      "block5b_ same\n",
      "block5c_ same\n",
      "block6a_ ((2, 2), (2, 2))\n",
      "block6a_ valid\n",
      "block6b_ same\n",
      "block6c_ same\n",
      "block6d_ same\n",
      "block7a_ same\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 10s 215ms/step - loss: 1.7239 - sparse_categorical_accuracy: 0.3681 - val_loss: 1.7389 - val_sparse_categorical_accuracy: 0.4444\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 3s 149ms/step - loss: 0.9516 - sparse_categorical_accuracy: 0.6703 - val_loss: 1.0864 - val_sparse_categorical_accuracy: 0.6444\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 3s 150ms/step - loss: 0.6986 - sparse_categorical_accuracy: 0.7308 - val_loss: 0.8820 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 4s 163ms/step - loss: 0.5733 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.6625 - val_sparse_categorical_accuracy: 0.7778\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 3s 123ms/step - loss: 0.5687 - sparse_categorical_accuracy: 0.7967 - val_loss: 1.1071 - val_sparse_categorical_accuracy: 0.6889\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 3s 132ms/step - loss: 0.4533 - sparse_categorical_accuracy: 0.8407 - val_loss: 1.1141 - val_sparse_categorical_accuracy: 0.7111\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 4s 155ms/step - loss: 0.5204 - sparse_categorical_accuracy: 0.8132 - val_loss: 0.5766 - val_sparse_categorical_accuracy: 0.8222\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 0.5136 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.8597 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 3s 131ms/step - loss: 0.4398 - sparse_categorical_accuracy: 0.8571 - val_loss: 2.0487 - val_sparse_categorical_accuracy: 0.5778\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 3s 133ms/step - loss: 0.3435 - sparse_categorical_accuracy: 0.9011 - val_loss: 1.3703 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 3s 128ms/step - loss: 0.3657 - sparse_categorical_accuracy: 0.8901 - val_loss: 1.0945 - val_sparse_categorical_accuracy: 0.6889\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 3s 136ms/step - loss: 0.3126 - sparse_categorical_accuracy: 0.9011 - val_loss: 1.1341 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 4s 157ms/step - loss: 0.3573 - sparse_categorical_accuracy: 0.8516 - val_loss: 0.4664 - val_sparse_categorical_accuracy: 0.7778\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 3s 130ms/step - loss: 0.3520 - sparse_categorical_accuracy: 0.8736 - val_loss: 0.6746 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.2769 - sparse_categorical_accuracy: 0.8956 - val_loss: 1.4127 - val_sparse_categorical_accuracy: 0.6444\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 3s 134ms/step - loss: 0.2935 - sparse_categorical_accuracy: 0.8901 - val_loss: 1.2537 - val_sparse_categorical_accuracy: 0.7556\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 0.3754 - sparse_categorical_accuracy: 0.9066 - val_loss: 2.5220 - val_sparse_categorical_accuracy: 0.4889\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 3s 138ms/step - loss: 0.2682 - sparse_categorical_accuracy: 0.9121 - val_loss: 1.6902 - val_sparse_categorical_accuracy: 0.7111\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 0.3328 - sparse_categorical_accuracy: 0.8956 - val_loss: 0.9894 - val_sparse_categorical_accuracy: 0.8222\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 3s 136ms/step - loss: 0.3877 - sparse_categorical_accuracy: 0.8901 - val_loss: 1.3209 - val_sparse_categorical_accuracy: 0.6889\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 3s 130ms/step - loss: 0.2757 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.6942 - val_sparse_categorical_accuracy: 0.7778\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 3s 137ms/step - loss: 0.1590 - sparse_categorical_accuracy: 0.9451 - val_loss: 0.8577 - val_sparse_categorical_accuracy: 0.7111\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.1770 - sparse_categorical_accuracy: 0.9451 - val_loss: 0.7075 - val_sparse_categorical_accuracy: 0.7556\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 3s 136ms/step - loss: 0.2701 - sparse_categorical_accuracy: 0.8736 - val_loss: 0.8664 - val_sparse_categorical_accuracy: 0.8222\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 3s 134ms/step - loss: 0.1589 - sparse_categorical_accuracy: 0.9451 - val_loss: 0.9733 - val_sparse_categorical_accuracy: 0.8222\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 3s 138ms/step - loss: 0.1305 - sparse_categorical_accuracy: 0.9725 - val_loss: 1.4274 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 3s 133ms/step - loss: 0.1815 - sparse_categorical_accuracy: 0.9451 - val_loss: 0.9969 - val_sparse_categorical_accuracy: 0.6889\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.2744 - sparse_categorical_accuracy: 0.9011 - val_loss: 0.7772 - val_sparse_categorical_accuracy: 0.7778\n",
      "2/2 [==============================] - 1s 431ms/step - loss: 0.7772 - sparse_categorical_accuracy: 0.7778\n",
      "block1a_ same\n",
      "block2a_ ((1, 1), (1, 1))\n",
      "block2a_ valid\n",
      "block2b_ same\n",
      "block3a_ ((2, 2), (2, 2))\n",
      "block3a_ valid\n",
      "block3b_ same\n",
      "block4a_ ((1, 1), (1, 1))\n",
      "block4a_ valid\n",
      "block4b_ same\n",
      "block4c_ same\n",
      "block5a_ same\n",
      "block5b_ same\n",
      "block5c_ same\n",
      "block6a_ ((2, 2), (2, 2))\n",
      "block6a_ valid\n",
      "block6b_ same\n",
      "block6c_ same\n",
      "block6d_ same\n",
      "block7a_ same\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 9s 200ms/step - loss: 1.6099 - sparse_categorical_accuracy: 0.3956 - val_loss: 3.8637 - val_sparse_categorical_accuracy: 0.2222\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 0.9829 - sparse_categorical_accuracy: 0.6648 - val_loss: 4.3040 - val_sparse_categorical_accuracy: 0.1556\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 4s 166ms/step - loss: 0.6732 - sparse_categorical_accuracy: 0.7363 - val_loss: 2.5896 - val_sparse_categorical_accuracy: 0.4444\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 3s 123ms/step - loss: 0.5777 - sparse_categorical_accuracy: 0.8352 - val_loss: 3.2487 - val_sparse_categorical_accuracy: 0.4889\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 3s 135ms/step - loss: 0.6252 - sparse_categorical_accuracy: 0.8077 - val_loss: 3.4895 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.5768 - sparse_categorical_accuracy: 0.7967 - val_loss: 1.6769 - val_sparse_categorical_accuracy: 0.5111\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 0.5620 - sparse_categorical_accuracy: 0.8077 - val_loss: 1.6285 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.4886 - sparse_categorical_accuracy: 0.8736 - val_loss: 2.3722 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.3700 - sparse_categorical_accuracy: 0.8736 - val_loss: 1.0542 - val_sparse_categorical_accuracy: 0.7556\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 0.3630 - sparse_categorical_accuracy: 0.8901 - val_loss: 1.0816 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 4s 173ms/step - loss: 0.3339 - sparse_categorical_accuracy: 0.8901 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.7778\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.3311 - sparse_categorical_accuracy: 0.8681 - val_loss: 0.9413 - val_sparse_categorical_accuracy: 0.7556\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 3s 133ms/step - loss: 0.3314 - sparse_categorical_accuracy: 0.9066 - val_loss: 1.1767 - val_sparse_categorical_accuracy: 0.7111\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 3s 123ms/step - loss: 0.2593 - sparse_categorical_accuracy: 0.9011 - val_loss: 1.1061 - val_sparse_categorical_accuracy: 0.7556\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 3s 134ms/step - loss: 0.2643 - sparse_categorical_accuracy: 0.9176 - val_loss: 1.4378 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 0.1620 - sparse_categorical_accuracy: 0.9396 - val_loss: 1.4396 - val_sparse_categorical_accuracy: 0.6889\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 3s 135ms/step - loss: 0.2826 - sparse_categorical_accuracy: 0.9286 - val_loss: 1.1751 - val_sparse_categorical_accuracy: 0.7111\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.1623 - sparse_categorical_accuracy: 0.9560 - val_loss: 1.2295 - val_sparse_categorical_accuracy: 0.7556\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 3s 131ms/step - loss: 0.1263 - sparse_categorical_accuracy: 0.9505 - val_loss: 2.0325 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 0.1662 - sparse_categorical_accuracy: 0.9505 - val_loss: 1.8331 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 3s 136ms/step - loss: 0.1984 - sparse_categorical_accuracy: 0.9286 - val_loss: 2.0878 - val_sparse_categorical_accuracy: 0.6444\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 3s 132ms/step - loss: 0.3237 - sparse_categorical_accuracy: 0.8901 - val_loss: 1.5352 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 3s 126ms/step - loss: 0.2920 - sparse_categorical_accuracy: 0.9066 - val_loss: 2.2940 - val_sparse_categorical_accuracy: 0.6222\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 3s 134ms/step - loss: 0.2634 - sparse_categorical_accuracy: 0.9176 - val_loss: 2.7584 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 3s 126ms/step - loss: 0.2545 - sparse_categorical_accuracy: 0.9286 - val_loss: 2.1661 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 3s 134ms/step - loss: 0.3317 - sparse_categorical_accuracy: 0.9011 - val_loss: 2.1151 - val_sparse_categorical_accuracy: 0.6000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.1151 - sparse_categorical_accuracy: 0.6000\n",
      "block1a_ same\n",
      "block2a_ ((1, 1), (1, 1))\n",
      "block2a_ valid\n",
      "block2b_ same\n",
      "block3a_ ((2, 2), (2, 2))\n",
      "block3a_ valid\n",
      "block3b_ same\n",
      "block4a_ ((1, 1), (1, 1))\n",
      "block4a_ valid\n",
      "block4b_ same\n",
      "block4c_ same\n",
      "block5a_ same\n",
      "block5b_ same\n",
      "block5c_ same\n",
      "block6a_ ((2, 2), (2, 2))\n",
      "block6a_ valid\n",
      "block6b_ same\n",
      "block6c_ same\n",
      "block6d_ same\n",
      "block7a_ same\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 9s 186ms/step - loss: 1.5926 - sparse_categorical_accuracy: 0.4560 - val_loss: 3.5958 - val_sparse_categorical_accuracy: 0.2222\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 3s 150ms/step - loss: 0.9689 - sparse_categorical_accuracy: 0.6758 - val_loss: 2.2208 - val_sparse_categorical_accuracy: 0.2444\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 3s 151ms/step - loss: 0.7205 - sparse_categorical_accuracy: 0.7418 - val_loss: 1.5266 - val_sparse_categorical_accuracy: 0.5556\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.4882 - sparse_categorical_accuracy: 0.8187 - val_loss: 1.1754 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 3s 134ms/step - loss: 0.4642 - sparse_categorical_accuracy: 0.8297 - val_loss: 1.5278 - val_sparse_categorical_accuracy: 0.6444\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.5630 - sparse_categorical_accuracy: 0.8297 - val_loss: 1.9287 - val_sparse_categorical_accuracy: 0.5556\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 3s 134ms/step - loss: 0.5620 - sparse_categorical_accuracy: 0.8132 - val_loss: 2.3966 - val_sparse_categorical_accuracy: 0.6222\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.5227 - sparse_categorical_accuracy: 0.7912 - val_loss: 1.5592 - val_sparse_categorical_accuracy: 0.6889\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 4s 167ms/step - loss: 0.5103 - sparse_categorical_accuracy: 0.8187 - val_loss: 1.0956 - val_sparse_categorical_accuracy: 0.7556\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 3s 123ms/step - loss: 0.3728 - sparse_categorical_accuracy: 0.8901 - val_loss: 2.1151 - val_sparse_categorical_accuracy: 0.5556\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 3s 136ms/step - loss: 0.2042 - sparse_categorical_accuracy: 0.9341 - val_loss: 1.4917 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 3s 133ms/step - loss: 0.2910 - sparse_categorical_accuracy: 0.9066 - val_loss: 1.9353 - val_sparse_categorical_accuracy: 0.6222\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 3s 131ms/step - loss: 0.3066 - sparse_categorical_accuracy: 0.9176 - val_loss: 1.4378 - val_sparse_categorical_accuracy: 0.7111\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 3s 135ms/step - loss: 0.5394 - sparse_categorical_accuracy: 0.8352 - val_loss: 1.1798 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 4s 155ms/step - loss: 0.3002 - sparse_categorical_accuracy: 0.9066 - val_loss: 1.0384 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 3s 132ms/step - loss: 0.2089 - sparse_categorical_accuracy: 0.9560 - val_loss: 1.1595 - val_sparse_categorical_accuracy: 0.6444\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.2154 - sparse_categorical_accuracy: 0.9231 - val_loss: 1.7001 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 3s 137ms/step - loss: 0.3048 - sparse_categorical_accuracy: 0.9176 - val_loss: 1.9201 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.3040 - sparse_categorical_accuracy: 0.8901 - val_loss: 2.1006 - val_sparse_categorical_accuracy: 0.5111\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 3s 136ms/step - loss: 0.2651 - sparse_categorical_accuracy: 0.9121 - val_loss: 1.4472 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 3s 138ms/step - loss: 0.2973 - sparse_categorical_accuracy: 0.9176 - val_loss: 1.9015 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 3s 128ms/step - loss: 0.2272 - sparse_categorical_accuracy: 0.9505 - val_loss: 1.6373 - val_sparse_categorical_accuracy: 0.5556\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 3s 135ms/step - loss: 0.1926 - sparse_categorical_accuracy: 0.9396 - val_loss: 1.4934 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 3s 139ms/step - loss: 0.2087 - sparse_categorical_accuracy: 0.9451 - val_loss: 1.3463 - val_sparse_categorical_accuracy: 0.7111\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.2088 - sparse_categorical_accuracy: 0.9121 - val_loss: 1.9499 - val_sparse_categorical_accuracy: 0.5556\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 3s 134ms/step - loss: 0.2828 - sparse_categorical_accuracy: 0.9176 - val_loss: 1.0424 - val_sparse_categorical_accuracy: 0.6222\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 3s 131ms/step - loss: 0.2185 - sparse_categorical_accuracy: 0.9231 - val_loss: 1.1274 - val_sparse_categorical_accuracy: 0.6889\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 3s 127ms/step - loss: 0.2584 - sparse_categorical_accuracy: 0.9176 - val_loss: 1.4013 - val_sparse_categorical_accuracy: 0.6444\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 3s 138ms/step - loss: 0.1928 - sparse_categorical_accuracy: 0.9341 - val_loss: 1.1319 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 3s 135ms/step - loss: 0.1584 - sparse_categorical_accuracy: 0.9451 - val_loss: 1.2569 - val_sparse_categorical_accuracy: 0.6667\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.2569 - sparse_categorical_accuracy: 0.6667\n",
      "block1a_ same\n",
      "block2a_ ((1, 1), (1, 1))\n",
      "block2a_ valid\n",
      "block2b_ same\n",
      "block3a_ ((2, 2), (2, 2))\n",
      "block3a_ valid\n",
      "block3b_ same\n",
      "block4a_ ((1, 1), (1, 1))\n",
      "block4a_ valid\n",
      "block4b_ same\n",
      "block4c_ same\n",
      "block5a_ same\n",
      "block5b_ same\n",
      "block5c_ same\n",
      "block6a_ ((2, 2), (2, 2))\n",
      "block6a_ valid\n",
      "block6b_ same\n",
      "block6c_ same\n",
      "block6d_ same\n",
      "block7a_ same\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model using K-fold cross-validation\n",
    "scores = []\n",
    "training_accuracy = []\n",
    "validation_accuracy = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "model_init()\n",
    "\n",
    "for train_idx, val_idx in kf.split(x_train_val):\n",
    "    X_train = tf.gather(x_train_val, train_idx)\n",
    "    y_train = tf.gather(y_train_val, train_idx)\n",
    "    X_val = tf.gather(x_train_val, val_idx)\n",
    "    y_val = tf.gather(y_train_val, val_idx)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs= 100, verbose=1, batch_size=8, \n",
    "                        callbacks=[early_stopping, checkpoint])\n",
    "\n",
    "    training_accuracy.append(history.history['sparse_categorical_accuracy'])\n",
    "    validation_accuracy.append(history.history['val_sparse_categorical_accuracy'])\n",
    "    training_loss.append(history.history['loss'])\n",
    "    validation_loss.append(history.history['val_loss'])\n",
    "    score = model.evaluate(X_val, y_val)\n",
    "    scores.append(score[1])\n",
    "    \n",
    "    model_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3ae736d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:44:00.262059Z",
     "start_time": "2023-04-09T20:44:00.259248Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy mean: 0.66 (std 0.07)\n"
     ]
    }
   ],
   "source": [
    "# Print the mean validation accuracy\n",
    "print('Validation accuracy mean: {:.2f} (std {:.2f})'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013aa747-2788-4c43-a743-c29c8c378de4",
   "metadata": {},
   "source": [
    "Calculating the **1 - Cohen's kappa** score of the trained model on the trained dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee7d5059-eb66-40fb-a848-bd2874e5cd5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights('best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb08a64b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T20:10:20.518612Z",
     "start_time": "2023-04-04T20:10:19.125881Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5142857142857142\n"
     ]
    }
   ],
   "source": [
    "predictions = np.zeros(len(y_test), dtype=np.int8)\n",
    "# inference loop\n",
    "for e, (image, target) in enumerate(zip(x_test, y_test)):\n",
    "    image = np.expand_dims(np.array(image), axis=0)\n",
    "    output = model.predict(image)\n",
    "    predictions[e] = np.squeeze(output).argmax()\n",
    "#Keras model score\n",
    "score_keras = 1 - cohen_kappa_score(y_test.numpy(), predictions)\n",
    "print(\"Score:\",score_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b9b6db-0771-41f7-9c83-29e26f8a9318",
   "metadata": {},
   "source": [
    "## Train - Validation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccf8e57-6fb7-443d-ba9a-adc43ba15c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eps_per_fold = [len(sub_list) for sub_list in training_accuracy]\n",
    "eps_per_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5865317a-83dc-42c1-a4f3-1abe577e63b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eps_per_fold_cum = list(accumulate(eps_per_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f6fb9-0369-4090-983d-58a4d79f5410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_accuracy = [element for sublist in training_accuracy for element in sublist]\n",
    "validation_accuracy = [element for sublist in validation_accuracy for element in sublist]\n",
    "training_loss = [element for sublist in training_loss for element in sublist]\n",
    "validation_loss = [element for sublist in validation_loss for element in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b0a9c-6f41-444e-ba23-cab449735fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eps_per_fold_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bdaa28-fd23-4ffc-9174-f51aa4ad8f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "for i in range(k):\n",
    "    xs.append(eps_per_fold_cum[i]+1)\n",
    "    ys.append(training_accuracy[eps_per_fold_cum[0]-1])\n",
    "# xs = [eps_per_fold_cum[0]+1, eps_per_fold_cum[1]+1, eps_per_fold_cum[2]+1, eps_per_fold_cum[3]+1, eps_per_fold_cum[4]+1]\n",
    "# ys = [training_accuracy[eps_per_fold_cum[0]-1], training_accuracy[eps_per_fold_cum[1]-1], training_accuracy[eps_per_fold_cum[2]-1],\n",
    "#          training_accuracy[eps_per_fold_cum[3]-1], training_accuracy[eps_per_fold_cum[4]-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e2e0b8-4b97-430f-a553-5962477fa2e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = list(range(1, len(training_accuracy) + 1))\n",
    "x2 = list(range(1, len(validation_accuracy) + 1))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(x1, training_accuracy, label='Training Accuracy')\n",
    "plt.plot(x2, validation_accuracy, label='Validation Accuracy')\n",
    "\n",
    "\n",
    "\n",
    "# Add points with labels\n",
    "for i in range(k-1):\n",
    "    plt.axvline(x=xs[i], color='red', linestyle='--')\n",
    "# plt.axvline(x=xs[0], color='red', linestyle='--')\n",
    "# plt.axvline(x=xs[1], color='red', linestyle='--')\n",
    "# plt.axvline(x=xs[2], color='red', linestyle='--')\n",
    "# plt.axvline(x=xs[3], color='red', linestyle='--')\n",
    "\n",
    "# Add annotations to the lines\n",
    "for i in range(k-1):\n",
    "    plt.annotate('Fold '+str(i+2), xy=(xs[i], 0.2), xytext=(xs[i]+1, 0.15),\n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'))\n",
    "\n",
    "# plt.annotate('Fold 2', xy=(xs[0], 0.5), xytext=(xs[0]+1, 0.4),\n",
    "#              arrowprops=dict(facecolor='black', arrowstyle='->'))\n",
    "# plt.annotate('Fold 3', xy=(xs[1], 0.5), xytext=(xs[1]+1, 0.4),\n",
    "#              arrowprops=dict(facecolor='black', arrowstyle='->'))\n",
    "# plt.annotate('Fold 4', xy=(xs[2], 0.5), xytext=(xs[2]+1, 0.4),\n",
    "#              arrowprops=dict(facecolor='black', arrowstyle='->'))\n",
    "# plt.annotate('Fold 5', xy=(xs[3], 0.5), xytext=(xs[3]+1, 0.4),\n",
    "#              arrowprops=dict(facecolor='black', arrowstyle='->'))\n",
    "# plt.axvline(x=xs[4], color='red', linestyle='--')\n",
    "# plt.scatter(xs, ys, color='red')\n",
    "# plt.annotate('Point 1', (2, 4), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "# plt.annotate('Point 2', (4, 8), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Enable the grid\n",
    "# plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bfe481-c074-4e42-857b-4e0df70be766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1073ff0-8023-4446-9287-711b255c8486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6914a879-ea49-4d8c-aa12-22231573d2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a741c-626d-4480-acf2-0e18892a05ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4480c0e-72c2-418c-af05-2d47ae530e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab82b9af-129b-4795-9411-60ba573f9656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718f5fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T20:42:39.783353Z",
     "start_time": "2023-04-09T20:42:39.220320Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Load the Model without any weight initialization\n",
    "# model = EfficientNetLiteB0(classes=num_classes, weights=None, input_shape=input_shape, classifier_activation=None)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9ed0f4-bd3f-45bd-b135-b0332086e2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f6c73b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T19:46:06.491070Z",
     "start_time": "2022-10-30T19:46:06.274124Z"
    }
   },
   "outputs": [],
   "source": [
    "## Saving model\n",
    "# model.save_weights('/home/ramez/Politechnika_Slaska_MSc/Thesis/Competition/submission/submit_19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0adb32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T19:40:44.823406Z",
     "start_time": "2022-10-30T19:40:43.780920Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = EfficientNetLiteB0(classes=num_classes, weights=None, input_shape=input_shape, classifier_activation=None)\n",
    "# # model = EfficientNetLiteB0(include_top=False, classes=num_classes, weights='imagenet', input_shape=input_shape, classifier_activation=None)\n",
    "# model.load_weights('/home/ramez/Politechnika_Slaska_MSc/Thesis/Competition/submission/model_patterns_20epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d26b2b",
   "metadata": {},
   "source": [
    "The model will be now compiled and tested again. You should get the same score as before saving and loading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e0e495",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T14:01:38.000493Z",
     "start_time": "2022-10-08T14:01:36.169912Z"
    }
   },
   "outputs": [],
   "source": [
    "# #Model shall be compiled before testing.\n",
    "# model.compile()\n",
    "\n",
    "# #Creating empty predictions\n",
    "# predictions = np.zeros(len(y_test), dtype=np.int8)\n",
    "# # inference loop\n",
    "# for e, (image, target) in enumerate(zip(x_test, y_test)):\n",
    "#     image = np.expand_dims(np.array(image), axis=0)\n",
    "#     output = model.predict(image)\n",
    "#     predictions[e] = np.squeeze(output).argmax()\n",
    "# #Keras model score\n",
    "# score_keras = 1 - cohen_kappa_score(y_test.numpy(), predictions)\n",
    "# print(\"Score:\",score_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82416ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eedf3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786276ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b71e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:20:06.668315Z",
     "start_time": "2022-10-12T18:20:06.652610Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd4279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
